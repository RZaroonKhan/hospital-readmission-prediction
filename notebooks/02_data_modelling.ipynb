{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b26f0c3",
   "metadata": {},
   "source": [
    "# Modeling â€” Predicting 30-Day Hospital Readmission\n",
    "\n",
    "**Goal:**  \n",
    "Build and evaluate machine learning models to predict whether a patient will be readmitted to the hospital within 30 days of discharge, using the cleaned dataset.\n",
    "\n",
    "**Key steps in this notebook:**\n",
    "1. **Load cleaned dataset**.\n",
    "2. **Separate features & target** (`readmit_30`).\n",
    "3. **Remove identifiers and leakage columns**.\n",
    "4. **Preprocess features**:\n",
    "   - One-Hot Encode categorical variables.\n",
    "   - Scale numeric features for linear models.\n",
    "5. **Split data** using stratification to maintain class balance.\n",
    "6. **Baseline models**:\n",
    "   - Logistic Regression (`class_weight='balanced'`)\n",
    "   - Random Forest (`class_weight='balanced_subsample'`)\n",
    "7. **Evaluate models** using ROC AUC and Precision-Recall AUC.\n",
    "8. **Tune decision threshold** to balance recall and precision.\n",
    "9. **Save trained models** for future use (e.g., dashboard or app).\n",
    "\n",
    "**Why this matters:**\n",
    "Accurately identifying high-risk patients for 30-day readmission can help hospitals target interventions, reduce costs, and improve patient outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5071089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 48)\n",
      "X shape: (101766, 44) y positive rate: 0.1116\n",
      "Categorical: 33 | Numeric: 11\n",
      "LR ROC AUC: 0.6444\n",
      "LR PR AUC (AP): 0.2046\n",
      "Best F1 threshold: 0.5633 F1: 0.2649\n",
      "Threshold for ~60% recall: 0.4794 Recall: 0.6002 Precision: 0.1598\n",
      "\n",
      "Classification report @ best F1 threshold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.914     0.789     0.847     18083\n",
      "           1      0.196     0.409     0.265      2271\n",
      "\n",
      "    accuracy                          0.747     20354\n",
      "   macro avg      0.555     0.599     0.556     20354\n",
      "weighted avg      0.834     0.747     0.782     20354\n",
      "\n",
      "Confusion matrix @ best F1 threshold\n",
      "[[14275  3808]\n",
      " [ 1343   928]]\n",
      "RF ROC AUC: 0.6758\n",
      "RF PR AUC (AP): 0.2193\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Load the cleaned dataset \n",
    "clean_path = Path(\"../data/diabetic_data_clean.csv\")\n",
    "df_clean = pd.read_csv(clean_path)\n",
    "\n",
    "# Work on a modeling copy so df_clean stays pristine\n",
    "df_model = df_clean.copy()\n",
    "\n",
    "print(df_model.shape)\n",
    "df_model.head(3)\n",
    "\n",
    "\n",
    "TARGET = 'readmit_30'\n",
    "\n",
    "# IDs / high-risk leakage columns to drop from features:\n",
    "# - encounter_id & patient_nbr are unique IDs (no predictive value)\n",
    "# - readmitted is the raw multi-class label we derived target from\n",
    "id_or_leak_cols = [c for c in ['encounter_id','patient_nbr','readmitted'] if c in df_model.columns]\n",
    "\n",
    "X = df_model.drop(columns=id_or_leak_cols + [TARGET])\n",
    "y = df_model[TARGET]\n",
    "\n",
    "print(\"X shape:\", X.shape, \"y positive rate:\", y.mean().round(4))\n",
    "\n",
    "# Column typing & encoders\n",
    "\n",
    "# Identify column types\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "print(\"Categorical:\", len(cat_cols), \"| Numeric:\", len(num_cols))\n",
    "\n",
    "# Build preprocessors\n",
    "categorical = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "numeric = StandardScaler(with_mean=False)  # with_mean=False because we may use sparse matrices\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical, cat_cols),\n",
    "        ('num', numeric, num_cols),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "# Stratified split because of imbalance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.mean().round(4), y_test.mean().round(4)\n",
    "\n",
    "model_lr = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=None))\n",
    "])\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "proba_lr = model_lr.predict_proba(X_test)[:,1]\n",
    "print(\"LR ROC AUC:\", round(float(roc_auc_score(y_test, proba_lr)), 4))\n",
    "print(\"LR PR AUC (AP):\", round(float(average_precision_score(y_test, proba_lr)), 4))\n",
    "\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba_lr)\n",
    "\n",
    "# Strategy A: maximize F1\n",
    "f1s = []\n",
    "for t in thr:\n",
    "    yhat = (proba_lr >= t).astype(int)\n",
    "    f1s.append(f1_score(y_test, yhat))\n",
    "best_idx = int(np.argmax(f1s))\n",
    "best_thr_f1 = thr[best_idx]\n",
    "print(\"Best F1 threshold:\", round(float(best_thr_f1), 4), \"F1:\", round(float(np.max(f1s)),4))\n",
    "\n",
    "# Strategy B (optional): pick threshold for desired recall (e.g., ~0.60)\n",
    "target_recall = 0.60\n",
    "rec_idx = np.argmin(np.abs(rec[:-1] - target_recall))\n",
    "thr_recall = thr[rec_idx]\n",
    "print(\"Threshold for ~60% recall:\", round(float(thr_recall),4), \"Recall:\", round(float(rec[rec_idx]),4), \"Precision:\", round(float(prec[rec_idx]),4))\n",
    "\n",
    "# Evaluate at best F1 threshold\n",
    "yhat_best = (proba_lr >= best_thr_f1).astype(int)\n",
    "print(\"\\nClassification report @ best F1 threshold\")\n",
    "print(classification_report(y_test, yhat_best, digits=3))\n",
    "\n",
    "print(\"Confusion matrix @ best F1 threshold\")\n",
    "print(confusion_matrix(y_test, yhat_best))\n",
    "\n",
    "model_rf = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight='balanced_subsample',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "proba_rf = model_rf.predict_proba(X_test)[:,1]\n",
    "print(\"RF ROC AUC:\", round(float(roc_auc_score(y_test, proba_rf)), 4))\n",
    "print(\"RF PR AUC (AP):\", round(float(average_precision_score(y_test, proba_rf)), 4))\n",
    "\n",
    "def plot_roc_pr(y_true, proba, label):\n",
    "    fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    prec, rec, _ = precision_recall_curve(y_true, proba)\n",
    "    ap = average_precision_score(y_true, proba)\n",
    "\n",
    "    # ROC\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC={roc_auc:.3f})')\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # PR\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec, label=f'{label} (AP={ap:.3f})')\n",
    "    baseline = y_true.mean()\n",
    "    plt.hlines(baseline, 0, 1, linestyles='--', label=f'Baseline Prevalence={baseline:.3f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_pr(y_test, proba_lr, \"LogReg\")\n",
    "plot_roc_pr(y_test, proba_rf, \"RandForest\")\n",
    "\n",
    "artifacts_dir = Path(\"artifacts\")\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(model_lr, artifacts_dir / \"model_lr.joblib\")\n",
    "joblib.dump(model_rf, artifacts_dir / \"model_rf.joblib\")\n",
    "\n",
    "print(\"Saved models to artifacts/\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
