{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad171c80",
   "metadata": {},
   "source": [
    "# Phase 4: Model Tuning & Explainability â€” Predicting 30-Day Hospital Readmission\n",
    "\n",
    "**Goal:**  \n",
    "Improve baseline model performance from Phase 3 through hyperparameter tuning, probability calibration, and model explainability.\n",
    "\n",
    "**Key steps in this notebook:**\n",
    "1. **Load cleaned dataset** from Phase 2.\n",
    "2. **Reuse preprocessing pipeline** from Phase 3 (encoding + scaling).\n",
    "3. **Hyperparameter tuning**:\n",
    "   - Logistic Regression (`GridSearchCV`, scoring by Precision-Recall AUC)\n",
    "   - Random Forest (`GridSearchCV`, scoring by Precision-Recall AUC)\n",
    "4. **Evaluate tuned models**:\n",
    "   - ROC AUC\n",
    "   - Precision-Recall AUC\n",
    "   - Best decision threshold (F1-optimized)\n",
    "5. **Probability calibration** (isotonic) for trustworthy risk scores.\n",
    "6. **Explainability with SHAP**:\n",
    "   - Global feature importance\n",
    "   - Individual prediction explanations\n",
    "7. **Save final model and configuration** for deployment.\n",
    "\n",
    "**Why this matters:**  \n",
    "Tuned and interpretable models are essential for healthcare use cases.  \n",
    "They ensure better recall of high-risk patients while giving clinicians insights into *why* a model predicts a readmission, increasing trust and adoption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc669b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "df_clean = pd.read_csv(Path(\"../data/diabetic_data_clean.csv\"))\n",
    "TARGET = \"readmit_30\"\n",
    "X = df_clean.drop(columns=[c for c in [\"encounter_id\",\"patient_nbr\",\"readmitted\", TARGET] if c in df_clean.columns])\n",
    "y = df_clean[TARGET]\n",
    "\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols),\n",
    "     (\"num\", StandardScaler(with_mean=False), num_cols)],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
